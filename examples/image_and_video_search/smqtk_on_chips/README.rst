
************************
Image Search Using SMQTK
************************

.. image:: http://www.viametoolkit.org/wp-content/uploads/2018/01/search_ex.png
   :scale: 30
   :align: center
   :target: https://github.com/Kitware/VIAME/tree/master/examples/image_and_video_search/smqtk_on_chips

| Building and running `this example`_ requires: 
|
|  (a) The python packages: numpy, pymongo
|  (b) Linux or Mac systems, Windows is not fully supported. 
|  (c) A VIAME build with the following flags enabled:
|        - VIAME_ENABLE_SMQTK
|        - VIAME_ENABLE_CAFFE
|        - VIAME_ENABLE_CUDA (Optional, but desired for performance)
|        - VIAME_ENABLE_YOLO (Optional, for detector ingest example (c))
|  (d) An installation of MongoDB to run the web GUI client 
|      (https://docs.mongodb.com/manual/administration/install-on-linux/)
|
| The system can either be configured to perform queries via: 
|
| (a) Indexing descriptors around each full input image as-is.
| (b) Tiling up each input image into fixed-size tiles. 
| (c) Indexing descriptors around detections generated by arbitrary detectors. 

.. _this example: https://github.com/Kitware/VIAME/tree/master/examples/image_and_video_search/smqtk_on_chips


First, reset_database.sh should be called to initialize a new database. 

Next, depending on which indexing paradigm you are using, one of the 3 ingesting shell
scripts can be called (ingest_[].sh).

Which ingesting paradigm you want to use depends on a few factors: does your object
take up the entire image? Use (a). Are your object(s) a fixed known size in your image?
Use (b). Are your objects multiple scales and do you have a detector which works decently
on your dataset? Use (c).

After ingesting data, you want to launch the web-GUI service (launch_gui_backend.sh), and connect
to the GUI via going to the default website 'http://0.0.0.0:5000/', at least if you didn't change any
hosting settings. The default GUI log in is username: demo, password: demo after which
you can log in, perform image queries, and iterative refinement on the results to generate
an improved model for your initial query.
