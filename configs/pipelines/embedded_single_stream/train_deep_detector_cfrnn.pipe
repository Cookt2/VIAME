# ============================== GLOBAL PROPERTIES =================================
# global pipeline config
#
config _pipeline:_edge
   :capacity                                   10

# ==================================================================================
process in_adapt
 :: input_adapter

process out_adapt
 :: output_adapter

# ==================================================================================

process random_grey
  :: image_filter
  :filter:type                                 vxl_convert_image

  block filter:vxl_convert_image
    :format                                    byte
    :random_greyscale                          0.25
    :force_three_channel                       true
  endblock

connect from in_adapt.image
        to   random_grey.image

process random_hue
  :: image_filter
  :filter:type                                 ocv_random_hue_shift

  block filter:ocv_random_hue_shift
    :trigger_percent                           0.40
    :hue_range                                 10.0
    :rgb_shift_range                           25.0
  endblock

connect from random_grey.image
        to   random_hue.image

process image_writer
 :: image_writer
 :image_writer:type                             vxl
 :image_writer:vxl:split_channels               false

connect from random_hue.image
        to   image_writer.image

# ==============================================================================

process tracks_to_detections
  :: convert_tracks_to_detections

process detector_trainer
  :: train_detector
  #  Algorithm to use for 'detector_trainer'.
  #  Must be one of the following options: darket, scallop_tk, mmdet, ocv_windowed
  trainer:type = ocv_windowed

  block trainer:ocv_windowed
    # Directory for all files used in training
    train_directory = deep_training
    # Windowing mode, can be disabled, maintain_ar, scale, chip, adaptive
    mode = adaptive
    # Image scaling factor used when mode is scale or chip
    scale = 1.25
    # When in chip mode, the chip width.
    chip_width = 1333
    # When in chip mode, the chip height.
    chip_height = 800
    # When in chip mode, the chip step size between chips.
    chip_step_height = 1100
    # When in chip mode, the chip step size between chips.
    chip_step_width = 600
    # If using adaptive selection, total pixel count at which we start to chip
    chip_adaptive_thresh = 2000000
    # Image reader type
    image_reader:type = vxl
  endblock

  block trainer:ocv_windowed:trainer
    # Trainer type
    type = mmdet
    # Configuration File
    relativepath mmdet:config_file = ../models/cfrnn_train.py
    # Seed Weights
    relativepath mmdet:seed_weights = ../models/cfrnn_seed.pth
    # Pipeline template file.
    relativepath mmdet:pipeline_template = ../templates/detector_cfrnn.pipe
    # Training temp directory
    mmdet:train_directory = deep_training
    # GPU Count, set as -1 to auto-detect and use maximum
    mmdet:gpu_count = -1
    # Launch type, can be: none, pytorch, slurm, or mpi
    mmdet:launcher = none
    # Random numeric seed for weights
    mmdet:random_seed = none
    # Should validation be run every epoch?
    mmdet:validate = false
  endblock

connect from in_adapt.object_track_set
        to   tracks_to_detections.object_track_set
connect from in_adapt.timestamp
        to   tracks_to_detections.timestamp

connect from in_adapt.image
        to   detector_trainer.image
connect from tracks_to_detections.detected_object_set
        to   detector_trainer.detected_object_set

connect from detector_trainer.object_track_set
        to   out_adapt.object_track_set

# -- end of file --
